service: tabelog-scraping
frameworkVersion: "2"

provider:
  name: aws
  runtime: python3.8
  region: ap-northeast-1
  lambdaHashingVersion: 20201221
  environment:
    GET_URL_REQUEST_SQS_URL: { Ref: GetUrlRequestQueue }
    SCRAPE_REQUEST_SQS_URL: { Ref: ScrapeRequestQueue }
  iam:
    role:
      statements:
        - Effect: Allow
          Action:
            - s3:*
          Resource:
            - "arn:aws:s3:::tabelog-scraping-input/*"
            - "arn:aws:s3:::tabelog-scraping-output/*"

        - Effect: "Allow"
          Action:
            - dynamodb:*
          Resource:
            - "arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/TabelogRstUrl"
            - "arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/TabelogRstData"

        - Effect: "Allow"
          Action:
            - "sqs:*"
          Resource:
            - "arn:aws:sqs:${opt:region, self:provider.region}:*:get_url_request"
            - "arn:aws:sqs:${opt:region, self:provider.region}:*:scrape_request"

plugins:
  - serverless-python-requirements

functions:
  publish_get_url_request_by_s3:
    handler: src/publish_get_url_request_by_s3.handler
    events:
      - s3:
          bucket: "tabelog-scraping-input"
          event: s3:ObjectCreated:*
          existing: true

  publish_get_url_request_by_http:
    handler: src/publish_get_url_request_by_http.handler
    events:
      - http:
          path: url
          method: get
          cors: true

  get_url:
    handler: src/get_url.handler
    events:
      - sqs:
          arn: { Fn::GetAtt: [GetUrlRequestQueue, Arn] }

  scrape:
    handler: src/scrape.handler
    events:
      - sqs:
          arn: { Fn::GetAtt: [ScrapeRequestQueue, Arn] }

  publish_scrape_request:
    handler: src/publish_scrape_request.handler
    events:
      - http:
          path: scrape
          method: get
          cors: true

  dump_to_csv:
    handler: src/dump_to_csv.handler
    events:
      - http:
          path: csv
          method: get
          cors: true

resources:
  Resources:
    # S3
    # InputBucket:
    #   Type: AWS::S3::Bucket
    #   Properties:
    #     BucketName: "tabelog-scraping-input"
    OutputBucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: "tabelog-scraping-output"

    # SQS
    GetUrlRequestQueue:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: "get_url_request"
    ScrapeRequestQueue:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: "scrape_request"

    # DynamoDB
    TabelogRstUrlTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: TabelogRstUrl
        AttributeDefinitions:
          - AttributeName: url
            AttributeType: S
        KeySchema:
          - AttributeName: url
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1
    TabelogRstDataTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: TabelogRstData
        AttributeDefinitions:
          - AttributeName: url
            AttributeType: S
        KeySchema:
          - AttributeName: url
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1

custom:
  pythonRequirements:
    pythonBin: python3
